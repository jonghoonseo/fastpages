
var documents = [{
    "id": 0,
    "url": "https://jonghoonseo.github.io/site/404.html",
    "title": "",
    "body": " 404 Page not found :(  The requested page could not be found. "
    }, {
    "id": 1,
    "url": "https://jonghoonseo.github.io/site/about/",
    "title": "About Me",
    "body": "This website is powered by fastpages 1.       a blogging platform that natively supports Jupyter notebooks in addition to other formats.  &#8617;    "
    }, {
    "id": 2,
    "url": "https://jonghoonseo.github.io/site/",
    "title": "",
    "body": "This site is built with fastpages, An easy to use blogging platform with extra features for Jupyter Notebooks.  fastpages automates the process of creating blog posts via GitHub Actions, so you don’t have to fuss with conversion scripts.  A full list of features can be found on GitHub. You can edit the index. html file to change this content. Posts"
    }, {
    "id": 3,
    "url": "https://jonghoonseo.github.io/site/search/",
    "title": "Search",
    "body": "          "
    }, {
    "id": 4,
    "url": "https://jonghoonseo.github.io/site/categories/",
    "title": "Tags",
    "body": "{% if site. categories. size &gt; 0 %} Contents: {% assign categories = “” | split:”” %} {% for c in site. categories %}  {% assign categories = categories | push: c[0] %} {% endfor %} {% assign categories = categories | sort_natural %}  {% for category in categories %}  {{ category }} {% endfor %} {% for category in categories %}   &lt;h3 id = {{ category }} &gt;&lt;/i&gt; {{ category }}&lt;/h3&gt;      {% for post in site. categories[category] %}    {% if post. hide != true %}    {%- assign date_format = site. minima. date_format | default: “%b %-d, %Y” -%}    &lt;article class= archive-item &gt;     &lt;p class= post-meta post-meta-title &gt;{{post. title}} • {{ post. date | date: date_format }}&lt;/p&gt;    &lt;/article&gt;    {% endif %}   {% endfor %} {% endfor %} {% endif %} "
    }, {
    "id": 5,
    "url": "https://jonghoonseo.github.io/site/robots.txt",
    "title": "",
    "body": "      Sitemap: {{ “sitemap. xml”   absolute_url }}   "
    }, {
    "id": 6,
    "url": "https://jonghoonseo.github.io/site/Bookmarks/",
    "title": "Bookmarks",
    "body": "2021/08/02 - BookmarksNLP:  pretrain. nlpedia. ai"
    }, {
    "id": 7,
    "url": "https://jonghoonseo.github.io/site/Word_Embeddings/",
    "title": "Word Embeddings",
    "body": "2020/12/30 -     &#53581;&#49828;&#53944;&#47484; &#49707;&#51088;&#47196; &#54364;&#54788;&#54616;&#44592; ML 모델들은 vector 를 입력으로 받기 때문에,text 처리 문제를 풀기 위해서는 '입력된 문자열을 숫자로 변환'하는 방법을 먼저 적용해야 한다. One-hot encoding : 첫번째 방법은 입력된 단어들을 one-hot 인코딩 하는 것이다. 이는 아래 그림과 같이, 모든 vocabulary 들을 각 bit 위치로 매핑하여 각 단어 위치의 bit 만 1로 set 하는 방법이다. 가장 단순하게 vector 를 만들 수 있다는 장점이 있으나,각 단어 사이의 관계를 매핑할 수 없다.  &#44033; &#45800;&#50612;&#47484; unique &#54620; &#49707;&#51088;&#47196; encoding : one-hot encoding 의 sparse 한 한계를 개선하기 위해 각 단어를 binary representation 에서 integer representation 으로 나타낸 방법이다. 하지만 여전히 각 단어 사이의 관계는 모델링 할 수 없고, 이로 인해 이를 학습한 모델의 파라미터 또한 interpretable 하지 않다 (또는 meaningful 하지 않다).  Word embeddings : 단어 임베딩 방법은 유사한 단어가 유사한 인코딩으로 나타나는 효율적이고 dense 한 표현법을 제공한다. 이 임베딩은 수동으로 임베딩 값을 설정했던 기존 방법과 다르게, 데이터로부터 학습된다. 학습 과정을 통해 단어는 특정한 길이의 (임베딩의 길이는 hparam) 실수 벡터로 나타난다. 인코딩된 임베딩의 길이가 길면 좀 더 상세한 관계를 표현할 수 있으나, 더 많은 데이터가 필요하고, 길이가 짧으면 덜 상세한 관계가 캡쳐된다.  Codes 본 예제에서는 문장에서 반응을 Classify 하는 Sentiment Classification 문제를 푼다. 이는 단어들의 연속으로부터 positive / negative 를 판단하는 Binary classification 문제이다.       from datetime import datetimeimport ioimport osimport reimport shutilimport stringfrom absl import loggingimport numpy as npimport tensorflow as tflogging. set_verbosity(1)    &#45936;&#51060;&#53552; &#51456;&#48708; : 본 문제를 위해서 IMDb 데이터셋을 사용한다. IMDb 데이터셋 다운로드tf. data. Dataset 생성Dataset 가속화IMDb &#45936;&#51060;&#53552;&#49483; &#45796;&#50868;&#47196;&#46300; :       IMDB_URL = &quot;https://ai. stanford. edu/~amaas/data/sentiment/aclImdb_v1. tar. gz&quot;def download_imdb(url=IMDB_URL, base_dir=base_dir):  dataset = tf. keras. utils. get_file(os. path. basename(url),                   url,                    untar=True,                   cache_dir=base_dir,                   cache_subdir=&#39;&#39;)  dataset_dir = os. path. join(os. path. dirname(dataset), &#39;aclImdb&#39;)  logging. info(&#39;%s&#39;, os. listdir(dataset_dir))  return dataset_dirif os. path. isdir(os. path. join(base_dir, &#39;aclImdb&#39;, &#39;train&#39;)):  dataset_dir = os. path. join(base_dir, &#39;aclImdb&#39;)else:  dataset_dir = download_imdb(IMDB_URL)  Downloading data from https://ai. stanford. edu/~amaas/data/sentiment/aclImdb_v1. tar. gz84131840/84125825 [==============================] - 4s 0us/stepINFO:absl:[&#39;imdbEr. txt&#39;, &#39;test&#39;, &#39;README&#39;, &#39;imdb. vocab&#39;, &#39;train&#39;]  tf. keras. utils. get_file API link: https://www. tensorflow. org/api_docs/python/tf/keras/utils/get_file cache_dir 에 파일이 없다면 다운로드 이 중 train/unsup 은 필요 없으니 삭제 (unsupervised dataset)       unsup_dir = os. path. join(dataset_dir, &#39;train&#39;, &#39;unsup&#39;)![ -d &quot;{unsup_dir}&quot; ] &amp;&amp; rm -rf &quot;{unsup_dir}&quot;!ls &quot;{dataset_dir}/train&quot;  labeledBow. feat pos		urls_neg. txt urls_unsup. txtneg		 unsupBow. feat	urls_pos. txt  IMDb &#45936;&#51060;&#53552;&#49483; &#44396;&#49457; :              import globimport pandas as pddata_dirs = [&#39;train/pos&#39;, &#39;train/neg&#39;, &#39;test/pos&#39;, &#39;test/neg&#39;]data_list = [os. path. join(dataset_dir, path) for path in data_dirs]data_list = [glob. glob(os. path. join(path, &#39;*&#39;)) for path in data_list]headers = [path. split(&#39;/&#39;) for path in data_dirs] # make multi-level index for Pandasheaders = pd. MultiIndex. from_tuples(headers)print(headers)data_list = pd. DataFrame(data_list, index=headers)print(data_list)assert not os. path. isdir(os. path. join(dataset_dir, &#39;train&#39;, &#39;unsup&#39;))print(&#39;-&#39; * 50)print(f&#39;num of data for each split: {data_list. shape[1]}&#39;)print(f&#39;total data: {data_list. shape[0] * data_list. shape[1]}&#39;)     MultiIndex([(&#39;train&#39;, &#39;pos&#39;),      (&#39;train&#39;, &#39;neg&#39;),      ( &#39;test&#39;, &#39;pos&#39;),      ( &#39;test&#39;, &#39;neg&#39;)],      )                  0   . . .               12499train pos . /aclImdb/train/pos/6836_9. txt . . .  . /aclImdb/train/pos/2563_10. txt   neg . /aclImdb/train/neg/3006_3. txt . . .  . /aclImdb/train/neg/5741_1. txttest pos . /aclImdb/test/pos/7998_10. txt . . .  . /aclImdb/test/pos/10682_10. txt   neg  . /aclImdb/test/neg/4245_4. txt . . .   . /aclImdb/test/neg/1213_3. txt[4 rows x 12500 columns]--------------------------------------------------num of data for each split: 12500total data: 50000  tf. data. Dataset &#49373;&#49457; : tf. keras. preprocessing. text_dataset_from_directory 사용하여 tf. data. Dataset 생성       def make_dataset(path, seed=0, batch_size=1024, validation_split=0. 2):  logging. debug(&#39;path: %s, seed: %d, batch_size: %d, validation_split: %f&#39;,         path, seed, batch_size, validation_split)  train_ds = tf. keras. preprocessing. text_dataset_from_directory(    path,    batch_size=batch_size,    validation_split=validation_split,     subset=&#39;training&#39;,    seed=seed)  val_ds = tf. keras. preprocessing. text_dataset_from_directory(    path,    batch_size=batch_size,    validation_split=validation_split,     subset=&#39;validation&#39;,    seed=seed)  return train_ds, val_dstrain_ds, val_ds = make_dataset(os. path. join(dataset_dir, &#39;train&#39;), seed=123)  DEBUG:absl:path: . /aclImdb/train, seed: 123, batch_size: 1024, validation_split: 0. 200000Found 25000 files belonging to 2 classes. Using 20000 files for training. Found 25000 files belonging to 2 classes. Using 5000 files for validation.   Dataset &#54869;&#51064; :       for text_batch, label_batch in train_ds. take(1): for i in range(5):  print(label_batch[i]. numpy(), text_batch. numpy()[i])  0 b&#34;Oh My God! Please, for the love of all that is holy, Do Not Watch This Movie! It it 82 minutes of my life I will never get back. Sure, I could have stopped watching half way through. But I thought it might get better. It Didn&#39;t. Anyone who actually enjoyed this movie is one seriously sick and twisted individual. No wonder us Australians/New Zealanders have a terrible reputation when it comes to making movies. Everything about this movie is horrible, from the acting to the editing. I don&#39;t even normally write reviews on here, but in this case I&#39;ll make an exception. I only wish someone had of warned me before I hired this catastrophe&#34;1 b&#39;This movie is SOOOO funny!!! The acting is WONDERFUL, the Ramones are sexy, the jokes are subtle, and the plot is just what every high schooler dreams of doing to his/her school. I absolutely loved the soundtrack as well as the carefully placed cynicism. If you like monty python, You will love this film. This movie is a tad bit &#34;grease&#34;esk (without all the annoying songs). The songs that are sung are likable; you might even find yourself singing these songs once the movie is through. This musical ranks number two in musicals to me (second next to the blues brothers). But please, do not think of it as a musical per say; seeing as how the songs are so likable, it is hard to tell a carefully choreographed scene is taking place. I think of this movie as more of a comedy with undertones of romance. You will be reminded of what it was like to be a rebellious teenager; needless to say, you will be reminiscing of your old high school days after seeing this film. Highly recommended for both the family (since it is a very youthful but also for adults since there are many jokes that are funnier with age and experience. &#39;0 b&#34;Alex D. Linz replaces Macaulay Culkin as the central figure in the third movie in the Home Alone empire. Four industrial spies acquire a missile guidance system computer chip and smuggle it through an airport inside a remote controlled toy car. Because of baggage confusion, grouchy Mrs. Hess (Marian Seldes) gets the car. She gives it to her neighbor, Alex (Linz), just before the spies turn up. The spies rent a house in order to burglarize each house in the neighborhood until they locate the car. Home alone with the chicken pox, Alex calls 911 each time he spots a theft in progress, but the spies always manage to elude the police while Alex is accused of making prank calls. The spies finally turn their attentions toward Alex, unaware that he has rigged devices to cleverly booby-trap his entire house. Home Alone 3 wasn&#39;t horrible, but probably shouldn&#39;t have been made, you can&#39;t just replace Macauley Culkin, Joe Pesci, or Daniel Stern. Home Alone 3 had some funny parts, but I don&#39;t like when characters are changed in a movie series, view at own risk. &#34;0 b&#34;There&#39;s a good movie lurking here, but this isn&#39;t it. The basic idea is good: to explore the moral issues that would face a group of young survivors of the apocalypse. But the logic is so muddled that it&#39;s impossible to get involved. &lt;br /&gt;&lt;br /&gt;For example, our four heroes are (understandably) paranoid about catching the mysterious airborne contagion that&#39;s wiped out virtually all of mankind. Yet they wear surgical masks some times, not others. Some times they&#39;re fanatical about wiping down with bleach any area touched by an infected person. Other times, they seem completely unconcerned. &lt;br /&gt;&lt;br /&gt;Worse, after apparently surviving some weeks or months in this new kill-or-be-killed world, these people constantly behave like total newbs. They don&#39;t bother accumulating proper equipment, or food. They&#39;re forever running out of fuel in the middle of nowhere. They don&#39;t take elementary precautions when meeting strangers. And after wading through the rotting corpses of the entire human race, they&#39;re as squeamish as sheltered debutantes. You have to constantly wonder how they could have survived this long. . . and even if they did, why anyone would want to make a movie about them. &lt;br /&gt;&lt;br /&gt;So when these dweebs stop to agonize over the moral dimensions of their actions, it&#39;s impossible to take their soul-searching seriously. Their actions would first have to make some kind of minimal sense. &lt;br /&gt;&lt;br /&gt;On top of all this, we must contend with the dubious acting abilities of Chris Pine. His portrayal of an arrogant young James T Kirk might have seemed shrewd, when viewed in isolation. But in Carriers he plays on exactly that same note: arrogant and boneheaded. It&#39;s impossible not to suspect that this constitutes his entire dramatic range. &lt;br /&gt;&lt;br /&gt;On the positive side, the film *looks* excellent. It&#39;s got an over-sharp, saturated look that really suits the southwestern US locale. But that can&#39;t save the truly feeble writing nor the paper-thin (and annoying) characters. Even if you&#39;re a fan of the end-of-the-world genre, you should save yourself the agony of watching Carriers. &#34;0 b&#39;I saw this movie at an actual movie theater (probably the $2. 00 one) with my cousin and uncle. We were around 11 and 12, I guess, and really into scary movies. I remember being so excited to see it because my cool uncle let us pick the movie (and we probably never got to do that again!) and sooo disappointed afterwards!! Just boring and not scary. The only redeeming thing I can remember was Corky Pigeon from Silver Spoons, and that wasn\&#39;t all that great, just someone I recognized. I\&#39;ve seen bad movies before and this one has always stuck out in my mind as the worst. This was from what I can recall, one of the most boring, non-scary, waste of our collective $6, and a waste of film. I have read some of the reviews that say it is worth a watch and I say, &#34;Too each his own&#34;, but I wouldn\&#39;t even bother. Not even so bad it\&#39;s good. &#39;  Dataset &#49444;&#51221; : 가속을 위해 Dataset 에 설정을 추가함 cache(): 데이터를 메모리에 올림. 데이터가 메모리 크기에 비해 크다면, on-disk 캐쉬를 생성할 수 있음. 이는 작은 여러개의 파일보다 성능이 높음. prefetch(): 학습 동안 데이터 전처리와 모델 실행을 overlap 함. data performance 디스크 캐쉬 등 여러 방법을 설명함       AUTOTUNE = tf. data. experimental. AUTOTUNEtrain_ds = train_ds. cache(). prefetch(buffer_size=AUTOTUNE)val_ds = val_ds. cache(). prefetch(buffer_size=AUTOTUNE)    Embedding layer : 임베딩 레이어는 입력으로 integer 인덱스를 받아서, 이에 해당하는 실수 vector 를 출력으로 반환하는 lookup table 으로 볼 수 있다. 여기서 임베딩의 크기는 하이퍼파라미터로 실험을 통해 조절이 필요하다. tf. keras. layers. Embedding tf. keras. layers. Embedding(  input_dim, output_dim, embeddings_initializer=&#39;uniform&#39;,  embeddings_regularizer=None, activity_regularizer=None,  embeddings_constraint=None, mask_zero=False, input_length=None, **kwargs)      EMBEDDING_SIZE = 5embedding_layer = tf. keras. layers. Embedding(1000, EMBEDDING_SIZE)    임베딩 레이어를 생성하면 처음에 랜덤한 값으로 초기화 되고,이후에는 backpropagation 을 통해 점차적으로 조절된다. 학습이 완료되면, 임베딩은 단어 사이의 유사도 를 인코딩한다.       result = embedding_layer(tf. constant([1,2,3]))result. numpy()  array([[-0. 00623799, 0. 02114315, 0. 03288199, -0. 02495058, 0. 04346171],    [-0. 00650135, 0. 03021416, -0. 01943512, 0. 03576155, -0. 02844778],    [ 0. 02554953, 0. 03821062, -0. 03710605, 0. 035557 , -0. 01577029]],   dtype=float32)  임베딩 레이어는 입력된 각 value 를 이에 해당하는 embedding 으로 변환하므로, 한 차원이 추가된다. 임베딩 사이즈가 $N$ 이라고 했을 때, \$(I, J, K)$ 차원의 입력이 들어오면 $(I, J, K, N)$ 차원이 출력된다.       input = np. random. randint(6, size=(2, 3))input = tf. convert_to_tensor(input, dtype=tf. int32)embeddings = embedding_layer(input)assert embeddings. shape == list(input. shape) + [EMBEDDING_SIZE]print(embeddings. shape)  (2, 3, 5)  variable length 를 입력으로 받기 위해서는 여러가지 표준화된 방법들이 있다. RNNAttentionpooling layerPadding + cropping여기서는 Pooling Layer 방법을 사용한다. Model : 본 예제에서는 단순한 형태의 모델을 사용한다. 모델의 구조는 아래와 같다. input: batch of string sentence (batch, -1) Text preprocessing layer: (batch, sequence_length, 1)standardizepadding/cropping 수행Embedding layer: (batch, sequence_length, embedding_dim)positive integer 입력값을 encoding 된 임베딩 벡터 값으로 변환Global 1D pooling layer: (batch, embedding_dim)sequence 차원으로 평균을 취함으로써 fixed-length 벡터를 만듦Fully connected layer: (batch, num_of_fc)Output layer: (batch, 1)Text Preprocessing : 모델에서 텍스트 전처리를 정의한다. 여기에서는 TextVectorization 클래스를 사용하는데,이 함수는 먼저 standardization을 수행하고, 이를 sequence_length 길이로 padding/cropping 한다. 최종적으로 dataset 을 넣어 adapt() 함수를 수행함으로써 데이터셋의 vocabulary 기반으로 단어 사전을 만든다.       def custom_standardization(input_data):  lowercase = tf. strings. lower(input_data)  stripped_html = tf. strings. regex_replace(lowercase, &#39;&lt;br /&gt;&#39;, &#39; &#39;)  return tf. strings. regex_replace(stripped_html,                  &#39;[%s]&#39; % re. escape(string. punctuation),                  &#39;&#39;)# Vocabulary size and number of words in a sequence. vocab_size = 10000sequence_length = 100# Use the text vectorization layer to normalize, split, and map strings to # integers. Note that the layer uses the custom standardization defined above. # Set maximum_sequence length as all samples are not of the same length. vectorize_layer = tf. keras. layers. experimental. preprocessing. TextVectorization(  standardize=custom_standardization,  max_tokens=vocab_size,  output_mode=&#39;int&#39;,  output_sequence_length=sequence_length)# Make a text-only dataset (no labels) and call adapt to build the vocabulary. text_ds = train_ds. map(lambda x, y: x)vectorize_layer. adapt(text_ds)    Model :       embedding_dim=16model = tf. keras. Sequential([ vectorize_layer, tf. keras. layers. Embedding(vocab_size, embedding_dim, name=&quot;embedding&quot;), tf. keras. layers. GlobalAveragePooling1D(), tf. keras. layers. Dense(16, activation=&#39;relu&#39;), tf. keras. layers. Dense(1)])    Compile and Training : 학습에 필요한 유틸들을 추가함       tensorboard_callback = tf. keras. callbacks. TensorBoard(log_dir=&quot;logs&quot;)    Compile 하고 학습 진행       model. compile(optimizer=&#39;adam&#39;,       loss=tf. keras. losses. BinaryCrossentropy(from_logits=True),       metrics=[&#39;accuracy&#39;])model. fit(  train_ds,  validation_data=val_ds,   epochs=15,  callbacks=[tensorboard_callback])  Epoch 1/1520/20 [==============================] - 5s 202ms/step - loss: 0. 6927 - accuracy: 0. 5037 - val_loss: 0. 6906 - val_accuracy: 0. 4886Epoch 2/1520/20 [==============================] - 2s 92ms/step - loss: 0. 6892 - accuracy: 0. 5037 - val_loss: 0. 6854 - val_accuracy: 0. 4886Epoch 3/1520/20 [==============================] - 2s 91ms/step - loss: 0. 6830 - accuracy: 0. 5037 - val_loss: 0. 6766 - val_accuracy: 0. 4886Epoch 4/1520/20 [==============================] - 2s 92ms/step - loss: 0. 6726 - accuracy: 0. 5037 - val_loss: 0. 6630 - val_accuracy: 0. 4886Epoch 5/1520/20 [==============================] - 2s 94ms/step - loss: 0. 6566 - accuracy: 0. 5037 - val_loss: 0. 6441 - val_accuracy: 0. 4886Epoch 6/1520/20 [==============================] - 2s 92ms/step - loss: 0. 6348 - accuracy: 0. 5039 - val_loss: 0. 6205 - val_accuracy: 0. 4962Epoch 7/1520/20 [==============================] - 2s 91ms/step - loss: 0. 6075 - accuracy: 0. 5357 - val_loss: 0. 5933 - val_accuracy: 0. 5784Epoch 8/1520/20 [==============================] - 2s 92ms/step - loss: 0. 5762 - accuracy: 0. 6235 - val_loss: 0. 5645 - val_accuracy: 0. 6404Epoch 9/1520/20 [==============================] - 2s 92ms/step - loss: 0. 5429 - accuracy: 0. 6898 - val_loss: 0. 5360 - val_accuracy: 0. 6824Epoch 10/1520/20 [==============================] - 2s 93ms/step - loss: 0. 5096 - accuracy: 0. 7375 - val_loss: 0. 5094 - val_accuracy: 0. 7176Epoch 11/1520/20 [==============================] - 2s 92ms/step - loss: 0. 4781 - accuracy: 0. 7664 - val_loss: 0. 4859 - val_accuracy: 0. 7412Epoch 12/1520/20 [==============================] - 2s 92ms/step - loss: 0. 4494 - accuracy: 0. 7903 - val_loss: 0. 4656 - val_accuracy: 0. 7550Epoch 13/1520/20 [==============================] - 2s 92ms/step - loss: 0. 4236 - accuracy: 0. 8096 - val_loss: 0. 4485 - val_accuracy: 0. 7652Epoch 14/1520/20 [==============================] - 2s 91ms/step - loss: 0. 4008 - accuracy: 0. 8228 - val_loss: 0. 4342 - val_accuracy: 0. 7760Epoch 15/1520/20 [==============================] - 2s 90ms/step - loss: 0. 3805 - accuracy: 0. 8354 - val_loss: 0. 4223 - val_accuracy: 0. 7866&lt;tensorflow. python. keras. callbacks. History at 0x7f7761f350f0&gt;  모델 구조는 아래와 같다.       model. summary()  Model: &#34;sequential&#34;_________________________________________________________________Layer (type)         Output Shape       Param #  =================================================================text_vectorization (TextVect (None, 100)        0     _________________________________________________________________embedding (Embedding)    (None, 100, 16)      160000  _________________________________________________________________global_average_pooling1d (Gl (None, 16)        0     _________________________________________________________________dense (Dense)        (None, 16)        272    _________________________________________________________________dense_1 (Dense)       (None, 1)         17    =================================================================Total params: 160,289Trainable params: 160,289Non-trainable params: 0_________________________________________________________________  학습 진행은 아래와 같다.       %load_ext tensorboard%tensorboard --logdir logs    (loss 감소를 보니 좀 더 진행해도 괜찮았을듯) &#54617;&#49845;&#46108; Embedding &#52628;&#52636; &#48143; &#51200;&#51109; : 상기와 같이 학습된 embedding 을 추출하고 저장하여 추후에 사용하도록 한다. embedding 의 구조는 (vocab_size, embedding_dimension) 의 형태를 가진다. embedding layer 의 weight 값을 가져오는 방법은 get_layer() 와 get_weights() 를 사용하는 것이다. 그리고, TextVectorization 레이어 클래스의 get_vocabulary() 함수는 vocabulary 의 각 token 에 대한 meta 정보를 가져온다.       def get_embedding(model,         embedding_layer_name=&#39;embedding&#39;,         vectorize_layer_name=&#39;text_vectorization&#39;):  weights = model. get_layer(embedding_layer_name). get_weights()[0]  meta = model. get_layer(vectorize_layer_name). get_vocabulary()  return weights, metaweights, vocab = get_embedding(model, vectorize_layer_name=vectorize_layer. name)    추출한 embedding 을 저장하기 위해서는 Embedding Projector 를 사용한다. 상기 추출한 weight 와 meta 정보를 tab separated format 으로 저장하여 업로드하면 된다.       def save_embedding(weights, meta, log_dir=&#39;. &#39;):  out_v = io. open(os. path. join(log_dir, &#39;vectors. tsv&#39;), &#39;w&#39;, encoding=&#39;utf-8&#39;)  out_m = io. open(os. path. join(log_dir, &#39;metadata. tsv&#39;), &#39;w&#39;, encoding=&#39;utf-8&#39;)  for index, word in enumerate(meta):    if index == 0: continue # skip 0, it&#39;s padding.     vec = weights[index]     out_v. write(&#39;\t&#39;. join([str(x) for x in vec]) + &quot;\n&quot;)    out_m. write(word + &quot;\n&quot;)  out_v. close()  out_m. close()save_embedding(weights, vocab)    Embedding Projector in Colab : https://www. tensorflow. org/tensorboard/tensorboard_projector_plugin에서 보면 바로 Colab tensorboard 상에서 embedding 을 visualize 할 수 있다.       log_dir=&#39;/logs/imdb-example/&#39;if not os. path. exists(log_dir):  os. makedirs(log_dir)save_embedding(weights, vocab, log_dir=log_dir)    여기서는 weights 를 checkpoint 로 저장한다.       weights = tf. Variable(weights)# Create a checkpoint from embedding, the filename and key are# name of the tensor. checkpoint = tf. train. Checkpoint(embedding=weights)checkpoint. save(os. path. join(log_dir, &quot;embedding. ckpt&quot;))!ls /logs/imdb-example  checkpoint			   metadata. tsvembedding. ckpt-1. data-00000-of-00001 projector_config. pbtxtembedding. ckpt-1. index		   vectors. tsv  새로 configuration       from tensorboard. plugins import projector# Set up configconfig = projector. ProjectorConfig()embedding = config. embeddings. add()# The name of the tensor will be suffixed by `/. ATTRIBUTES/VARIABLE_VALUE`embedding. tensor_name = &quot;embedding/. ATTRIBUTES/VARIABLE_VALUE&quot;embedding. metadata_path = &#39;metadata. tsv&#39;projector. visualize_embeddings(log_dir, config)    Tensorboard로 visualize       %tensorboard --logdir /logs/imdb-example/  Reusing TensorBoard on port 6007 (pid 223), started 0:03:18 ago. (Use &#39;!kill 223&#39; to kill it. )  "
    }, {
    "id": 8,
    "url": "https://jonghoonseo.github.io/site/Hello_Jupyter/",
    "title": "Hello Jupyter",
    "body": "2020/12/26 -     Overview This is my very first Jupyter notebook post for fastpages. I hope this page is built to valid markdown post. To verify build validity, I will test the following topics in this article: Import packagesThird-party packages: ex. numpyMy own packages: ex. hello_world. pyPlay wavsDisplay imageImport Packages In this chapter, I'll test importing packages. Basically, fastpages provides a build-in Docker image to launch Jupyter Notebook. However, for package manage aspect, it makes cumbersome to expand packages - defining packages in Dockerfile , building it again, and so on. So, I recommend you not to use the docker image (actually, I removed execution from the docker-compose, see d5930ef756d849dee01cb9e6037972b4fadadab3) Instead of docker image, I recommend to use local Jupyter Notebook and pyenv pairs or Google Colab Third-party Packages :       import numpy as npnp. arange(100)  array([ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,    17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,    34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,    51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,    68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,    85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99])  Custom Packages :       !cat hello_world. pyimport hello_worldprint(&#39;-&#39; * 20)hello_world. say(&#39;JSeo&#39;)  &#34;&#34;&#34;Hello World Library&#34;&#34;&#34;def say(name):  &#34;&#34;&#34;Say `hello world` with given name&#34;&#34;&#34;  print(f&#39;hello world {name}!&#39;)--------------------hello world JSeo!  Play wavs To play wavs in Jupyter notebook, we can use IPython. display. Audio class.       import IPython. display as ipd!wget https://file-examples-com. github. io/uploads/2017/11/file_example_WAV_1MG. wavipd. Audio(&#39;file_example_WAV_1MG. wav&#39;)  --2020-12-27 15:09:02-- https://file-examples-com. github. io/uploads/2017/11/file_example_WAV_1MG. wavResolving file-examples-com. github. io (file-examples-com. github. io). . . 185. 199. 108. 153, 185. 199. 110. 153, 185. 199. 111. 153, . . . Connecting to file-examples-com. github. io (file-examples-com. github. io)|185. 199. 108. 153|:443. . . connected. HTTP request sent, awaiting response. . . 200 OKLength: 1073218 (1. 0M) [audio/wav]Saving to: ‘file_example_WAV_1MG. wav’file_example_WAV_1M 100%[===================&gt;]  1. 02M --. -KB/s  in 0. 05s  2020-12-27 15:09:03 (22. 2 MB/s) - ‘file_example_WAV_1MG. wav’ saved [1073218/1073218]                            Your browser does not support the audio element.                  Display image To show image in Jupyter notebook, we can use IPython. display. Image class       !wget https://cdn. pixabay. com/photo/2020/12/03/05/23/lion-5799523_960_720. jpgipd. Image(&#39;lion-5799523_960_720. jpg&#39;)  --2020-12-27 15:13:35-- https://cdn. pixabay. com/photo/2020/12/03/05/23/lion-5799523_960_720. jpgResolving cdn. pixabay. com (cdn. pixabay. com). . . 104. 18. 21. 183, 104. 18. 20. 183, 2606:4700::6812:14b7, . . . Connecting to cdn. pixabay. com (cdn. pixabay. com)|104. 18. 21. 183|:443. . . connected. HTTP request sent, awaiting response. . . 200 OKLength: 194358 (190K) [image/jpeg]Saving to: ‘lion-5799523_960_720. jpg’lion-5799523_960_72 100%[===================&gt;] 189. 80K --. -KB/s  in 0. 02s  2020-12-27 15:13:35 (12. 1 MB/s) - ‘lion-5799523_960_720. jpg’ saved [194358/194358]  "
    }, {
    "id": 9,
    "url": "https://jonghoonseo.github.io/site/test/",
    "title": "Fastpages Notebook Blog Post",
    "body": "2020/02/20 -     About This notebook is a demonstration of some of capabilities of fastpages with notebooks. With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! Front Matter : The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: #  My Title &gt;  Awesome summary - toc:true- branch: master- badges: true- comments: true- author: Hamel Husain &amp; Jeremy Howard- categories: [fastpages, jupyter]Setting toc: true will automatically generate a table of contentsSetting badges: true will automatically include GitHub and Google Colab links to your notebook. Setting comments: true will enable commenting on your blog post, powered by utterances. The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. Markdown Shortcuts : A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. A #hide_input comment at the top of any code cell will only hide the input of that cell.     The comment #hide_input was used to hide the code that produced this.   put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it:              import pandas as pdimport altair as alt       put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it:              cars = &#39;https://vega. github. io/vega-datasets/data/cars. json&#39;movies = &#39;https://vega. github. io/vega-datasets/data/movies. json&#39;sp500 = &#39;https://vega. github. io/vega-datasets/data/sp500. csv&#39;stocks = &#39;https://vega. github. io/vega-datasets/data/stocks. csv&#39;flights = &#39;https://vega. github. io/vega-datasets/data/flights-5k. json&#39;       place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it:       print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. &#39;)         The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.     Interactive Charts With Altair : Charts made with Altair remain interactive.  Example charts taken from this repo, specifically this notebook. Example 1: DropDown :       # use specific hard-wired values as the initial selected valuesselection = alt. selection_single(  name=&#39;Select&#39;,  fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;],  init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;},  bind={&#39;Major_Genre&#39;: alt. binding_select(options=genres), &#39;MPAA_Rating&#39;: alt. binding_radio(options=mpaa)}) # scatter plot, modify opacity based on selectionalt. Chart(df). mark_circle(). add_selection(  selection). encode(  x=&#39;Rotten_Tomatoes_Rating:Q&#39;,  y=&#39;IMDB_Rating:Q&#39;,  tooltip=&#39;Title:N&#39;,  opacity=alt. condition(selection, alt. value(0. 75), alt. value(0. 05)))    Example 2: Tooltips :       alt. Chart(df). mark_circle(). add_selection(  alt. selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;])). encode(  alt. X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;),  alt. Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt. Axis(minExtent=30)),#   y=alt. Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement  tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;]). properties(  width=500,  height=400)    Example 3: More Tooltips :       label = alt. selection_single(  encodings=[&#39;x&#39;], # limit selection to x-axis value  on=&#39;mouseover&#39;, # select on mouseover events  nearest=True,  # select data point nearest the cursor  empty=&#39;none&#39;   # empty selection includes no data points)# define our base line chart of stock pricesbase = alt. Chart(). mark_line(). encode(  alt. X(&#39;date:T&#39;),  alt. Y(&#39;price:Q&#39;, scale=alt. Scale(type=&#39;log&#39;)),  alt. Color(&#39;symbol:N&#39;))alt. layer(  base, # base line chart    # add a rule mark to serve as a guide line  alt. Chart(). mark_rule(color=&#39;#aaa&#39;). encode(    x=&#39;date:T&#39;  ). transform_filter(label),    # add circle marks for selected time points, hide unselected points  base. mark_circle(). encode(    opacity=alt. condition(label, alt. value(1), alt. value(0))  ). add_selection(label),  # add white stroked text to provide a legible background for labels  base. mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2). encode(    text=&#39;price:Q&#39;  ). transform_filter(label),  # add text labels for stock prices  base. mark_text(align=&#39;left&#39;, dx=5, dy=-5). encode(    text=&#39;price:Q&#39;  ). transform_filter(label),    data=stocks). properties(  width=500,  height=400)    Data Tables : You can display tables per the usual way in your blog:       df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;,   &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]]. head()           Title   Worldwide_Gross   Production_Budget   Distributor   MPAA_Rating   IMDB_Rating   Rotten_Tomatoes_Rating         0   The Land Girls   146083. 0   8000000. 0   Gramercy   R   6. 1   NaN       1   First Love, Last Rites   10876. 0   300000. 0   Strand   R   6. 9   NaN       2   I Married a Strange Person   203134. 0   250000. 0   Lionsgate   None   6. 8   NaN       3   Let's Talk About Sex   373615. 0   300000. 0   Fine Line   None   NaN   13. 0       4   Slam   1087521. 0   1000000. 0   Trimark   R   3. 4   62. 0     Images : Local Images : You can reference local images and they will be copied and rendered on your blog automatically.  You can include these with the following markdown syntax: ![](my_icons/fastai_logo. png) Remote Images : Remote images can be included with the following markdown syntax: ![](https://image. flaticon. com/icons/svg/36/36686. svg) Animated Gifs : Animated Gifs work, too! ![](https://upload. wikimedia. org/wikipedia/commons/7/71/ChessPawnSpecialMoves. gif) Captions : You can include captions with markdown images like this: ![](https://www. fast. ai/images/fastai_paper/show_batch. png  Credit: https://www. fast. ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/ ) Other Elements GitHub Flavored Emojis : Typing I give this post two :+1:! will render this: I give this post two :+1:! Tweetcards : Typing &gt; twitter: https://twitter. com/jakevdp/status/1204765621767901185?s=20 will render this:  Altair 4. 0 is released! https://t. co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t. co/roXmzcsT58 . . . read on for some highlights. pic. twitter. com/vWJ0ZveKbZ &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Youtube Videos : Typing &gt; youtube: https://youtu. be/XfoYk_Z5AkI will render this:   Boxes / Callouts : Typing &gt; Warning: There will be no second warning! will render this:    Warning: There will be no second warning! Typing &gt; Important: Pay attention! It's important. will render this:    Important: Pay attention! It&#8217;s important. Typing &gt; Tip: This is my tip. will render this:    Tip: This is my tip. Typing &gt; Note: Take note of this. will render this:    Note: Take note of this. Typing &gt; Note: A doc link to [an example website: fast. ai](https://www. fast. ai/) should also work fine. will render in the docs:    Note: A doc link to an example website: fast. ai should also work fine. Footnotes : You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: For example, here is a footnote {% fn 1 %}. And another {% fn 2 %}{{ 'This is the footnote. ' | fndetail: 1 }}{{ 'This is the other footnote. You can even have a [link](www. github. com)!' | fndetail: 2 }}For example, here is a footnote 1. And another 2 1. This is the footnote. ↩ 2. This is the other footnote. You can even have a link!↩ "
    }, {
    "id": 10,
    "url": "https://jonghoonseo.github.io/site/test-markdown-post/",
    "title": "An Example Markdown Post",
    "body": "2020/01/14 - Example Markdown PostBasic setup: Jekyll requires blog post files to be named according to the following format: YEAR-MONTH-DAY-filename. md Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. . md is the file extension for markdown files. The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. Basic formatting: You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: Lists: Here’s a list:  item 1 item 2And a numbered list:  item 1 item 2Boxes and stuff:  This is a quotation    You can include alert boxes…and…    You can include info boxesImages: Code: You can format text and code per usual General preformatted text: # Do a thingdo_thing()Python code and output: # Prints '2'print(1+1)2Formatting text as shell commands: echo  hello world . /some_script. sh --option  value wget https://example. com/cat_photo1. pngFormatting text as YAML: key: value- another_key:  another value Tables:       Column 1   Column 2         A thing   Another thing   Tweetcards: Altair 4. 0 is released! https://t. co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t. co/roXmzcsT58 . . . read on for some highlights. pic. twitter. com/vWJ0ZveKbZ &mdash; Jake VanderPlas (@jakevdp) December 11, 2019Footnotes:       This is the footnote.  &#8617;    "
    }];

var idx = lunr(function () {
    this.ref('id')
    this.field('title')
    this.field('body')

    documents.forEach(function (doc) {
        this.add(doc)
    }, this)
});
function lunr_search(term) {
    document.getElementById('lunrsearchresults').innerHTML = '<ul></ul>';
    if(term) {
        document.getElementById('lunrsearchresults').innerHTML = "<p>Search results for '" + term + "'</p>" + document.getElementById('lunrsearchresults').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>No results found...</li>";
        }
    }
    return false;
}

function lunr_search(term) {
    $('#lunrsearchresults').show( 400 );
    $( "body" ).addClass( "modal-open" );
    
    document.getElementById('lunrsearchresults').innerHTML = '<div id="resultsmodal" class="modal fade show d-block"  tabindex="-1" role="dialog" aria-labelledby="resultsmodal"> <div class="modal-dialog shadow-lg" role="document"> <div class="modal-content"> <div class="modal-header" id="modtit"> <button type="button" class="close" id="btnx" data-dismiss="modal" aria-label="Close"> &times; </button> </div> <div class="modal-body"> <ul class="mb-0"> </ul>    </div> <div class="modal-footer"><button id="btnx" type="button" class="btn btn-danger btn-sm" data-dismiss="modal">Close</button></div></div> </div></div>';
    if(term) {
        document.getElementById('modtit').innerHTML = "<h5 class='modal-title'>Search results for '" + term + "'</h5>" + document.getElementById('modtit').innerHTML;
        //put results on the screen.
        var results = idx.search(term);
        if(results.length>0){
            //console.log(idx.search(term));
            //if results
            for (var i = 0; i < results.length; i++) {
                // more statements
                var ref = results[i]['ref'];
                var url = documents[ref]['url'];
                var title = documents[ref]['title'];
                var body = documents[ref]['body'].substring(0,160)+'...';
                document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML + "<li class='lunrsearchresult'><a href='" + url + "'><span class='title'>" + title + "</span><br /><small><span class='body'>"+ body +"</span><br /><span class='url'>"+ url +"</span></small></a></li>";
            }
        } else {
            document.querySelectorAll('#lunrsearchresults ul')[0].innerHTML = "<li class='lunrsearchresult'>Sorry, no results found. Close & try a different search!</li>";
        }
    }
    return false;
}
    
$(function() {
    $("#lunrsearchresults").on('click', '#btnx', function () {
        $('#lunrsearchresults').hide( 5 );
        $( "body" ).removeClass( "modal-open" );
    });
});